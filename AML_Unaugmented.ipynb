{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RefineX/Change-Detection/blob/main/AML_Unaugmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing libraries & mounting google drive"
      ],
      "metadata": {
        "id": "kJ7KEKPh_FW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install image-classifiers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gRRiXuberuln",
        "outputId": "203adb9f-49c7-4bbb-da60-3d86d2de6384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting image-classifiers\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers) (1.21.6)\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Downloader\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resize = \"512\" #@param [\"1024\", \"512\", \"256\"]\n",
        "crop = \"256\" #@param [\"1024\", \"512\", \"256\"]\n",
        "\n",
        "data_link_dict = {\n",
        "    'S2Looking': {\n",
        "      '1024_512': \"1-0_vcODMYmyYIY_uhMcs97aAk2OJVduq&confirm=t\",\n",
        "      '1024_256': \"1-0mVd6BjKnG3LXhYkbyxdx0-dtRKY6KO&confirm=t\",\n",
        "      '512_512': \"1-6WOmE0LTJ4Z31EphmA0L8QY5NMMllsT&confirm=t\",\n",
        "      '512_256': \"1-7NSOmHTsDpkEtbgt_N4VSgipCo5kr3a&confirm=t\",\n",
        "      '256_256': \"1-8x5d5DrNsgJ5eAOYyKwi91g8knGeRjQ&confirm=t\",\n",
        "      '1024_1024': \"1GzrgMwJKguXSWSfFsBSC2qSr52fVEc7W&confirm=t\"\n",
        "    },\n",
        "    'LEVIRCD_Plus': {\n",
        "      '1024_512': \"1-22GjfF8mlLFNyoJaa6_GMJRfTCoGZyc&confirm=t\",\n",
        "      '1024_256': \"1-2r-zCCfQjLRtwwXMGPYAxEJcTS8Hp80&confirm=t\",\n",
        "      '512_512': \"1-43scZrxe3Q_PH2EnBRuc_6l9O9WjPs2&confirm=t\",\n",
        "      '512_256': \"1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\",\n",
        "      '256_256': \"1-69cdgqlcXunt5vrCR9jRvcMkpPNzYWr&confirm=t\",\n",
        "      '1024_1024': \"1nyPJZGGOL7o8A0m0rGw7wyu2BFIxC4SD&confirm=t\"\n",
        "    }\n",
        "}\n",
        "\n",
        "import os\n",
        "if os.path.exists(f'Data/{dataset}/{resize}_{crop}'):\n",
        "  print('This dataset already exists.')\n",
        "else:\n",
        "  gdown_link = data_link_dict[dataset][f'{resize}_{crop}']\n",
        "  !gdown \"{gdown_link}\"\n",
        "  print('Unzipping...',end='')\n",
        "  !unzip -q \"{resize}_{crop}.zip\"\n",
        "  print('Done.\\nDeleting zip...',end='')\n",
        "  !rm \"{resize}_{crop}.zip\"\n",
        "  print('Done.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jdXkHvK6gGr7",
        "outputId": "c90bb162-c631-4fd3-b954-b0c32f9d45e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5oC0xV36S4K5VMiQuwheWoyMt1ymYb9&confirm=t\n",
            "To: /content/512_256.zip\n",
            "100% 317M/317M [00:01<00:00, 169MB/s]\n",
            "Unzipping...Done.\n",
            "Deleting zip...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing dependencies"
      ],
      "metadata": {
        "id": "PTyzU26Q_QaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import cv2\n",
        "import random\n",
        "import shutil as sh"
      ],
      "metadata": {
        "id": "B9GQ_AA1i5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset Characteristics\n",
        "dataset = \"LEVIRCD_Plus\" #@param [\"S2Looking\", \"LEVIRCD_Plus\"]\n",
        "resized_size = \"512\" #@param [1024, 512, 256]\n",
        "crop_size = \"256\" #@param [1024, 512, 256]\n",
        "resized_size = int(resized_size)\n",
        "crop_size = int(crop_size)\n",
        "if dataset == 'S2Looking':\n",
        "  pre_image = 'Image1'\n",
        "  post_image = 'Image2'\n",
        "elif dataset == 'LEVIRCD_Plus':\n",
        "  pre_image = 'A'\n",
        "  post_image = 'B'\n",
        "label_image = 'label'\n",
        "PATH = f\"/content/Data/{dataset}/{resized_size}_{crop_size}\"\n",
        "Path('saved/models/').mkdir(parents=True, exist_ok=True)\n",
        "Path('saved/histories/').mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "AFi5x75Ek8IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subset selection for few-shot learning"
      ],
      "metadata": {
        "id": "Jw9bENQ3_c4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset Choice\n",
        "subset_percent = \"100\" #@param [\"10\", \"25\", \"50\", \"100\"]\n",
        "if subset_percent == \"100\":\n",
        "  PATH = PATH\n",
        "else:\n",
        "  Subset_PATH = PATH+\"_subset_{}\".format(subset_percent)\n",
        "  Path(Subset_PATH).mkdir(parents=True, exist_ok=True)\n",
        "  dirs = os.listdir(PATH)\n",
        "  subdirs = os.listdir(PATH+\"/\"+dirs[0])\n",
        "  for dir in dirs:\n",
        "    for subdir in subdirs:\n",
        "      Path(Subset_PATH+\"/\"+dir+\"/\"+subdir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  for dir in dirs:\n",
        "    img_list = os.listdir(PATH+\"/\"+dir+\"/\"+pre_image)\n",
        "    initial_count = len(img_list)\n",
        "    final_count = int(initial_count * int(subset_percent)/100)\n",
        "    random.seed(0)\n",
        "    subset_img_list = random.sample(img_list, final_count)\n",
        "    for subdir in subdirs:\n",
        "      for subset_img in subset_img_list:\n",
        "        if subdir == label_image:\n",
        "          source_path = PATH+\"/\"+dir+\"/\"+subdir+\"/\"+subset_img.replace('jpg','png')\n",
        "          destination_path = Subset_PATH+\"/\"+dir+\"/\"+subdir+\"/\"+subset_img.replace('jpg','png')\n",
        "        else:\n",
        "          source_path = PATH+\"/\"+dir+\"/\"+subdir+\"/\"+subset_img\n",
        "          destination_path = Subset_PATH+\"/\"+dir+\"/\"+subdir+\"/\"+subset_img\n",
        "        sh.copy(source_path, destination_path)\n",
        "  PATH = Subset_PATH"
      ],
      "metadata": {
        "id": "eXPquqiVW-SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check block for subset dataset split"
      ],
      "metadata": {
        "id": "LrVGUeHd_ifM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for mmm in ['train','val','test']:\n",
        "  print(os.listdir(f'/content/Data/{dataset}/{resized_size}_{crop_size}_subset_{subset_percent}/{mmm}/A')==os.listdir(f'/content/Data/{dataset}/{resized_size}_{crop_size}_subset_{subset_percent}/{mmm}/B'))\n",
        "  print([f.replace('jpg','png') for f in sorted(os.listdir(f'/content/Data/{dataset}/{resized_size}_{crop_size}_subset_{subset_percent}/{mmm}/A'))] == sorted(os.listdir(f'/content/Data/{dataset}/{resized_size}_{crop_size}_subset_{subset_percent}/{mmm}/label')))"
      ],
      "metadata": {
        "id": "6cMbZi_Cl5Hp",
        "outputId": "f0e65ab5-6c05-49a7-fa8c-9dcdef1d9224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining metrics"
      ],
      "metadata": {
        "id": "bTNDKS5s_z3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "\n",
        "def iou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou_value = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "def miou(y_true,y_pred):\n",
        "  y_pred = tf.argmax(y_pred,-1)\n",
        "  y_true = tf.argmax(y_true,-1)\n",
        "  tp = tf.cast(tf.reduce_sum(y_pred*y_true,axis=[1,2]), 'float32')\n",
        "  tn = tf.cast(tf.reduce_sum((1-y_pred)*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fp = tf.cast(tf.reduce_sum(y_pred*(1-y_true),axis=[1,2]), 'float32')\n",
        "  fn = tf.cast(tf.reduce_sum((1-y_pred)*y_true,axis=[1,2]), 'float32')\n",
        "  iou1 = (tp + 1e-14) / (tp + fp + fn + 1e-14)\n",
        "  iou2 = (tn + 1e-14) / (tn + fp + fn + 1e-14)\n",
        "  iou_value = (iou1 + iou2) / 2\n",
        "  return tf.reduce_mean(iou_value)\n",
        "\n",
        "# Losses"
      ],
      "metadata": {
        "id": "JGxDUbzFp6IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from classification_models.tfkeras import Classifiers\n",
        "import pickle\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "O3mqAH-HyxjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "epochs = 50\n",
        "es_patience = 15\n",
        "rLR_patience = 5\n",
        "lr = 1e-2\n",
        "optimizer = Adam(learning_rate = lr)\n",
        "loss = 'categorical_crossentropy'\n",
        "BATCH_SIZE = 16\n",
        "metrics = [iou, 'accuracy']"
      ],
      "metadata": {
        "id": "3UI_uqydsmA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 Data"
      ],
      "metadata": {
        "id": "q3wjGHs6hrsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions for Model #1\n",
        "def load(imageA_file):\n",
        "  imageA = tf.io.read_file(imageA_file)\n",
        "  imageA = tf.image.decode_png(imageA)[:,:,:3]\n",
        "\n",
        "  imageB_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{post_image}/')\n",
        "  imageB = tf.io.read_file(imageB_file)\n",
        "  imageB = tf.image.decode_jpeg(imageB)[:,:,:3]\n",
        "\n",
        "  label_file = tf.strings.regex_replace(imageA_file, f'/{pre_image}/', f'/{label_image}/')\n",
        "  label_file = tf.strings.regex_replace(label_file, '.jpg', '.png')\n",
        "  label = tf.io.read_file(label_file)\n",
        "  label = tf.image.decode_png(label)[:,:,0]\n",
        "\n",
        "  imageA = tf.cast(imageA,tf.float32)\n",
        "  imageB = tf.cast(imageB,tf.float32)\n",
        "  image = tf.concat([imageA,imageB],axis=-1)\n",
        "  label = tf.cast(label,tf.float32)\n",
        "  label = tf.stack([255-label,label],axis=-1)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def normalize(image, label):\n",
        "  image = image / 255\n",
        "  label = label / 255\n",
        "  return image, label\n",
        "\n",
        "def load_image(image_file):\n",
        "  image, label = load(image_file)\n",
        "  image, label = normalize(image, label)\n",
        "  return image, label\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(f'{PATH}/train/{pre_image}/*.jpg')\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "train_dataset_length = len(train_dataset)\n",
        "# train_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(f'{PATH}/val/{pre_image}/*.jpg')\n",
        "val_dataset = val_dataset.map(load_image)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "val_dataset_length = len(val_dataset)\n",
        "# val_dataset_length = int(np.ceil(len(os.listdir(f'{PATH}/train/{pre_image}/'))/BATCH_SIZE))\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(f'{PATH}/test/{pre_image}/*.jpg')\n",
        "test_dataset = test_dataset.map(load_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset_length = len(test_dataset)\n",
        "# test_dataset_length = len(os.listdir(f'{PATH}/train/{pre_image}/'))\n",
        "\n",
        "print(f'train_dataset_length: {train_dataset_length}, val_dataset_length: {val_dataset_length}, test_dataset_length: {test_dataset_length}')"
      ],
      "metadata": {
        "id": "7uCJTn1Ot3pm",
        "outputId": "485ffffa-c1bf-46b6-bcfc-7d767b54e6a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_length: 64, val_dataset_length: 16, test_dataset_length: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "UDElGWyhhuYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "def ef_model(input_shape = (256, 256, 6), backbone = 'resnet18'):\n",
        "\n",
        "  ResNet18, preprocess_input = Classifiers.get(backbone)\n",
        "  encoder = ResNet18(input_shape, weights=None,include_top=False)\n",
        "  encoder_output = encoder.output\n",
        "  skip_outputs = [encoder.get_layer(f).output for f in ['stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0']]\n",
        "\n",
        "  def conv_bn_relu(filters,x):\n",
        "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "  x = encoder_output\n",
        "  for i,skip_output in enumerate(skip_outputs):\n",
        "    x = UpSampling2D(name=f'up{i+1}')(x)\n",
        "    filters = skip_output.shape[-1]\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = conv_bn_relu(filters,x)\n",
        "    x = concatenate([x, skip_output])\n",
        "  x = UpSampling2D(name='up5')(x)\n",
        "  for filters in [32,32,16,16]:\n",
        "    x = conv_bn_relu(filters,x)\n",
        "  x = Conv2D(2, 1, activation = 'softmax', padding='same', kernel_initializer='he_uniform', dtype = 'float32')(x)\n",
        "  model = Model(inputs = encoder.inputs, outputs = x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "5AN_EYMubtCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "8eGr7d9tABFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model #1\n",
        "input_shape = (crop_size, crop_size, 6)\n",
        "backbone = 'resnet18'\n",
        "model = ef_model(input_shape, backbone)\n",
        "model_name = 'model_ef'\n",
        "model_path = f'saved/models/{dataset}_{backbone}_{model_name}_subset_50_unaug.h5'\n",
        "history_path = f'saved/histories/{dataset}_{backbone}_{model_name}_subset_50_unaug.pkl'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_iou', mode='max', save_best_only=True, verbose = 1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_iou', mode = 'max', factor=1/np.sqrt(10), patience = rLR_patience, min_lr=1e-6, verbose = 1)\n",
        "earlystopper = EarlyStopping(monitor='val_iou', mode = 'max', patience = es_patience, verbose=1)\n",
        "callbacks = [checkpoint, reduce_lr, earlystopper]\n",
        "optimizer = Adam(learning_rate = lr)\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n",
        "hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset, callbacks = callbacks)\n",
        "with open(history_path, 'wb') as file_pi:\n",
        "  pickle.dump(hist.history, file_pi)\n",
        "\n",
        "model.load_weights(model_path)\n",
        "_, test_iou, _ = model.evaluate(test_dataset)\n",
        "os.rename(model_path, model_path.replace('.h5',f'_{test_iou:.4f}.h5'))\n",
        "os.rename(history_path, history_path.replace('.pkl',f'_{test_iou:.4f}.pkl'))\n",
        "plt.plot(hist.history['iou'])\n",
        "plt.plot(hist.history['val_iou'])\n",
        "plt.title('model iou')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n27RJ_hKb0Hy",
        "outputId": "223490c1-1e63-4551-e9c5-9fec82b20965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1560 - iou: 0.2954 - accuracy: 0.9519\n",
            "Epoch 1: val_iou improved from -inf to 0.09506, saving model to saved/models/LEVIRCD_Plus_resnet18_model_ef_subset_50_unaug.h5\n",
            "64/64 [==============================] - 52s 354ms/step - loss: 0.1560 - iou: 0.2954 - accuracy: 0.9519 - val_loss: nan - val_iou: 0.0951 - val_accuracy: 0.7972 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move saved files to drive"
      ],
      "metadata": {
        "id": "7uqiwkibhyo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r saved_subset_50_unaug.zip saved/\n",
        "!cp saved_subset_50_unaug.zip /content/drive/MyDrive/saved_subset_50_unaug.zip"
      ],
      "metadata": {
        "id": "_maxz9GaWg2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}